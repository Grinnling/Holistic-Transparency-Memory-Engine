# Error Handler Service Audit
**Date Created:** October 31, 2025
**Purpose:** Audit all microservices for error handling gaps
**Goal:** Complete error centralization across the entire memory system

---

## Audit Scope

**Services to Audit:**
1. ‚úÖ rich_chat.py (CLI client) - COMPLETED
2. ‚è≥ working_memory/service.py - IN PROGRESS
3. ‚è≥ episodic_memory/service.py - PENDING
4. ‚è≥ curator/service.py - PENDING
5. ‚è≥ mcp_logger/service.py - PENDING
6. ‚è≥ api_server_bridge.py - PENDING

---

## Service 1: rich_chat.py (CLI Client)

**Status:** ‚úÖ COMPLETED
**Date Audited:** October 31, 2025
**File Location:** `/home/grinnling/Development/CODE_IMPLEMENTATION/rich_chat.py`

### Findings:
- ‚úÖ ErrorHandler imported and initialized
- ‚úÖ Critical `store_exchange()` wrapped with error_handler context manager
- ‚úÖ Silent data loss bug FIXED (tested and verified)
- ‚úÖ Alerts flow to React UI via `/errors` endpoint
- ‚úÖ Bare except blocks reviewed and documented with TODOs

### Remaining Items:
- üìù Curator validation - marked for future agent integration
- üìù LLM fallback - marked for multi-model integration
- üìù Service cleanup - logging added with learning period approach

### Test Results:
- ‚úÖ Test EH-2 (Silent Failure Fix) - PASSED
- ‚úÖ Test EH-3 (Alert Routing to React) - PASSED

---

## Service 2: working_memory/service.py

**Status:** ‚úÖ AUDIT COMPLETE - Integration Decision Needed
**Date Audited:** October 31, 2025
**File Location:** `/home/grinnling/Development/ACTIVE_SERVICES/docker_agent_environment/memory_system/working_memory/service.py`
**File Size:** 185 lines

### Initial Scan:
- Flask microservice with 5 endpoints
- Thread-safe buffer with locking
- Simple in-memory storage (list-based)
- Uses Python logging module

### Exception Blocks Found:
**Total: 4 exception handlers** (all properly caught)

1. **Line 58** - `get_working_memory()`
   - Catches: All exceptions
   - Handling: Logs error + returns 500 JSON response ‚úÖ

2. **Line 111** - `add_exchange()` (CRITICAL!)
   - Catches: All exceptions
   - Handling: Logs error + returns 500 JSON response ‚úÖ
   - **This is where data writes happen!**

3. **Line 133** - `clear_working_memory()`
   - Catches: All exceptions
   - Handling: Logs error + returns 500 JSON response ‚úÖ

4. **Line 175** - `update_buffer_size()`
   - Catches: All exceptions
   - Handling: Logs error + returns 500 JSON response ‚úÖ

### Error Handling Pattern:
**Current approach: PROPER!** ‚úÖ
```python
try:
    # operation
except Exception as e:
    logger.error(f"Error message: {e}")
    return jsonify({"status": "error", "message": str(e)}), 500
```

**What's good:**
- All exceptions are caught (not bare `except:`)
- All errors are logged via logger
- All errors return structured JSON responses
- HTTP 500 status codes properly set
- No silent failures!

### Critical Operations Identified:
1. **add_exchange()** - Writing user messages to buffer (CRITICAL - data loss risk)
2. **get_working_memory()** - Reading buffer (less critical, caller handles)
3. **clear_working_memory()** - Clearing buffer (less critical, idempotent)
4. **update_buffer_size()** - Config change (less critical)

### Integration Plan:
**Recommended: Option B - Structured Logging Only (NO ErrorHandler needed)**

**Reasoning:**
- This is an independent microservice (not coupled to rich_chat)
- Already has proper error handling
- Returns structured errors to caller
- Caller (rich_chat) already wraps these calls with ErrorHandler
- Adding ErrorHandler here would be redundant

**What's already working:**
- rich_chat calls `add_exchange()`
- rich_chat wraps that call with error_handler context manager
- If working_memory fails, rich_chat's error_handler catches it
- Error appears in UI

**What could be improved (OPTIONAL):**
- More detailed logging (include context like message length, buffer size)
- Structured logging format (JSON logs for parsing)
- Separate logger for critical vs debug operations

### Questions/Concerns:
**Q:** Should microservices have their own ErrorHandler instances?
**A:** No - they return errors, callers handle UI/alerting

**Q:** What about logger configuration?
**A:** Currently using basic Python logging - could enhance but not urgent

**Q:** Database failures?
**A:** This service uses in-memory storage - no DB to fail

---

## Service 3: episodic_memory/service.py

**Status:** ‚úÖ AUDIT COMPLETE - No Changes Needed
**Date Audited:** October 31, 2025
**File Location:** `/home/grinnling/Development/ACTIVE_SERVICES/docker_agent_environment/memory_system/episodic_memory/service.py`
**File Size:** 520 lines

### Initial Scan:
- Flask microservice with 9 endpoints
- SQLite database for persistent storage
- EpisodicMemoryService class handles business logic
- Request ID tracking for debugging

### Exception Blocks Found:
**Total: 14 exception handlers** (all properly caught)

**Flask Endpoints (all follow same pattern):**
1. Line 377 - `archive_conversation()` (CRITICAL - data write!)
2. Line 413 - `search_conversations()`
3. Line 440 - `get_conversation()`
4. Line 468 - `export_conversation()`
5. Line 490 - `get_recent_conversations()`
6. Line 510 - `get_service_stats()`

**EpisodicMemoryService class methods:**
7. Line 122 - `archive_conversation()` (DB write)
8. Line 142 - `_parse_timestamp()` (parsing helper)
9. Line 250 - `search_conversations()` (DB read)
10. Line 265 - `get_conversation()` (DB read)
11. Line 279 - `get_recent_conversations()` (DB read)
12. Line 287 - `export_conversation_text()` (DB read)
13. Line 309 - `get_service_stats()` (DB read)
14. Line 140 - ValueError catch (timestamp parsing)

### Error Handling Pattern:
**Current approach: PROPER!** ‚úÖ

**Flask endpoints pattern:**
```python
try:
    # operation
except Exception as e:
    logger.error(f"Error message (request: {g.request_id}): {e}")
    return jsonify({"status": "error", "message": str(e), "request_id": g.request_id}), 500
```

**Service class pattern:**
```python
try:
    # operation
except Exception as e:
    logger.error(f"Error message: {e}")
    raise  # Re-raise for Flask endpoint to handle
```

**What's good:**
- All exceptions properly caught and logged
- Request IDs tracked for debugging
- Structured JSON error responses
- Service class raises errors for endpoint layer to handle
- HTTP status codes properly set
- Database errors handled gracefully

### Critical Operations Identified:
1. **archive_conversation()** - Writing conversations to SQLite DB (CRITICAL!)
2. **search_conversations()** - Database queries (less critical)
3. **get_conversation()** - Single conversation retrieval (less critical)

### Integration Plan:
**Recommended: Option B - No Changes Needed** ‚úÖ

**Reasoning:**
- Independent microservice with proper error handling
- All errors logged with request IDs for tracing
- Structured error responses for callers
- Database operations properly wrapped
- Caller (MemoryHandler in rich_chat) handles UI alerting

**What's already working:**
- MemoryHandler calls episodic endpoints
- If episodic fails, MemoryHandler's error handling catches it
- Errors flow to error_handler in rich_chat
- User sees alerts in UI

**What's particularly good:**
- Request ID tracking (g.request_id) for debugging
- Service class separates business logic from HTTP layer
- Clear error messages with context

### Questions/Concerns:
**Q:** Database corruption or disk full scenarios?
**A:** SQLite errors are caught and logged - would need monitoring

**Q:** Should we add health checks for DB integrity?
**A:** Current health check exists - could enhance with DB validation

---

## Service 4: memory_curator/curator_service.py

**Status:** ‚úÖ AUDIT COMPLETE - Already Excellent!
**Date Audited:** October 31, 2025
**File Location:** `/home/grinnling/Development/ACTIVE_SERVICES/docker_agent_environment/memory_system/memory_curator/curator_service.py`
**File Size:** 484 lines

### Initial Scan:
- Flask microservice with 6 endpoints
- MemoryCurator class with business logic separation ‚úÖ
- Request ID tracking implemented ‚úÖ
- Validation engine for memory quality checks
- Group chat validation sessions

### Exception Blocks Found:
**Total: 6 exception handlers** (all properly caught)

**Flask Endpoints (all follow episodic pattern!):**
1. Line 328 - `validate_memory()` (CRITICAL - validation logic)
2. Line 360 - `start_group_chat()`
3. Line 400 - `add_chat_message()`
4. Line 427 - `get_chat_session()`
5. Line 454 - `get_validation_status()`
6. Line 474 - `get_curator_stats()`

### Error Handling Pattern:
**Current approach: EXCELLENT!** ‚úÖ‚úÖ‚úÖ

**Follows episodic pattern perfectly:**
```python
# Service class with business logic
class MemoryCurator:
    def validate_memory_exchange(self, exchange_data, validation_type):
        # Business logic here
        return validation_result

# Flask endpoint with request tracking
@app.route('/validate', methods=['POST'])
def validate_memory():
    try:
        validation_result = curator.validate_memory_exchange(exchange_data, validation_type)
        return jsonify({"status": "success", "validation": validation_result, "request_id": g.request_id})
    except Exception as e:
        logger.error(f"Error in memory validation (request: {g.request_id}): {e}")
        return jsonify({"status": "error", "message": str(e), "request_id": g.request_id}), 500
```

**What's excellent:**
- ‚úÖ MemoryCurator class separates business logic from HTTP
- ‚úÖ Request ID tracking on ALL endpoints
- ‚úÖ Structured JSON error responses
- ‚úÖ Proper logging with context
- ‚úÖ HTTP status codes correct
- ‚úÖ Clean separation of concerns
- ‚úÖ **THIS IS THE GOLD STANDARD!**

### Critical Operations Identified:
1. **validate_memory_exchange()** - Core validation logic (CRITICAL!)
2. **start_group_chat()** - Multi-party validation sessions
3. **add_chat_message()** - Chat session management

### Integration Plan:
**Recommended: No Changes Needed** ‚úÖ

**Reasoning:**
- Already follows best practices
- Service class + request IDs = perfect pattern
- This is what we want other services to look like!
- Independent microservice with proper error handling

**What's particularly excellent:**
- This service is the MODEL for how all services should be structured
- Clear business logic separation
- Request tracing built in
- Easy to test and maintain

### Note:
Curator will eventually become an AGENT (not a service). When that happens, error handling approach may need adjustment for agent-specific patterns.

---

## Service 5: mcp_logger/server.py + router.py

**Status:** ‚úÖ AUDIT COMPLETE - Different Pattern, Also Good!
**Date Audited:** October 31, 2025
**File Locations:**
- `/home/grinnling/Development/ACTIVE_SERVICES/docker_agent_environment/memory_system/mcp_logger/server.py` (246 lines)
- `/home/grinnling/Development/ACTIVE_SERVICES/docker_agent_environment/memory_system/mcp_logger/router.py`

### Initial Scan:
- Flask server with routing/proxy architecture
- MemoryRouter class handles request routing
- **Zero except blocks in server.py** - relies on router + errorhandlers
- Request ID tracking implemented ‚úÖ
- Auth decorators for security
- Global error handlers for 404/500

### Error Handling Architecture:
**Unique 3-layer approach:**

1. **Server Layer (server.py):**
   - Global `@app.errorhandler(404)` and `@app.errorhandler(500)`
   - No explicit try/except - clean endpoints
   - Request IDs tracked

2. **Router Layer (router.py):**
   - `route_store_request()` returns `(success: bool, result: Dict)`
   - Handles retries, timeouts, connection errors
   - Sophisticated error handling with specific exception types

3. **Logging Layer:**
   - Custom `router_logger` with categorized logging
   - Categories: SERVICE_ERROR, SERVICE_TIMEOUT, SERVICE_UNAVAILABLE, SERVICE_EXCEPTION

### Exception Blocks Found:
**Server: 0 explicit except blocks** (uses errorhandlers)
**Router: 7 exception handlers** (all properly caught)

**Router exceptions (sophisticated!):**
1. Line 105 - ValueError (JSON parsing)
2. Line 147 - `requests.exceptions.Timeout` (specific!)
3. Line 155 - `requests.exceptions.ConnectionError` (specific!)
4. Line 163 - Generic Exception catch-all
5. Line 260 - ValueError (recall parsing)
6. Line 313 - Generic Exception

### Error Handling Pattern:
**Current approach: SOPHISTICATED!** ‚úÖ

**Router pattern (with retries):**
```python
for attempt in range(service.retry_count):
    try:
        response = requests.post(url, json=data, timeout=service.timeout)
        if response.status_code == 200:
            return True, response.json()
        else:
            return False, {"error": f"Service returned {response.status_code}"}

    except requests.exceptions.Timeout:
        router_logger.log_warning("SERVICE_TIMEOUT", ...)
        if attempt == service.retry_count - 1:  # Last attempt
            return False, {"error": "Service timeout"}

    except requests.exceptions.ConnectionError:
        router_logger.log_warning("SERVICE_UNAVAILABLE", ...)
        if attempt == service.retry_count - 1:
            return False, {"error": "Service unavailable"}

    except Exception as e:
        router_logger.log_error("SERVICE_EXCEPTION", ...)
        return False, {"error": "Service error", "details": str(e)}
```

**Server pattern (clean delegation):**
```python
@app.route('/memory/store', methods=['POST'])
@log_request
def store_memory():
    data = request.get_json()
    success, result = memory_router.route_store_request(data)

    if success:
        return jsonify({'status': 'success', 'request_id': g.request_id, 'result': result})
    else:
        return jsonify({'status': 'error', 'request_id': g.request_id, 'error': result}), 500
```

**What's excellent:**
- ‚úÖ Specific exception catching (Timeout, ConnectionError) instead of generic
- ‚úÖ Retry logic with backoff
- ‚úÖ Request ID tracking
- ‚úÖ Clean server endpoints (no error handling clutter)
- ‚úÖ Router handles complexity
- ‚úÖ Categorized logging for debugging
- ‚úÖ Global error handlers for unexpected errors

### Critical Operations Identified:
1. **route_store_request()** - Proxying memory storage (CRITICAL!)
2. **route_recall_request()** - Proxying memory recall
3. **route_search_request()** - Proxying search queries

### Integration Plan:
**Recommended: No Changes Needed** ‚úÖ

**Reasoning:**
- Different architecture (proxy/router) requires different pattern
- Already has sophisticated error handling
- Request IDs tracked
- Specific exception catching is better than generic
- Retry logic adds resilience
- Clean separation: server (HTTP) vs router (business logic)

**What's particularly sophisticated:**
- **Retry logic** - Handles transient failures gracefully
- **Specific exceptions** - Different handling for timeout vs connection errors
- **Categorized logging** - Easy to trace different failure types
- **Clean delegation** - Server stays simple, router handles complexity

### Comparison to Standard Pattern:
**This uses "Proxy Pattern" instead of "Service Pattern":**
- Service Pattern: Business logic in service class, Flask wraps it
- Proxy Pattern: Router proxies to other services, Flask exposes routes

Both are valid! MCP Logger is a **router/gateway**, not a data service, so proxy pattern fits better.

### Questions/Concerns:
**Q:** Should router have request IDs too?
**A:** Currently server-level only - could pass through to router for deeper tracing

**Q:** Retry logic - exponential backoff?
**A:** Currently simple retry - could enhance with backoff

---

## Service 6: api_server_bridge.py

**Status:** ‚úÖ AUDIT COMPLETE - Hybrid Pattern with ErrorHandler Integration!
**Date Audited:** October 31, 2025
**File Location:** `/home/grinnling/Development/CODE_IMPLEMENTATION/api_server_bridge.py`
**File Size:** 552 lines

### Initial Scan:
- FastAPI bridge between React UI and rich_chat.py
- WebSocket support for real-time updates
- REST endpoints for chat, health, history, errors, memory operations, service management
- **Already integrates ErrorHandler** via shared instance
- Custom `track_error()` wrapper for React broadcasting
- Request ID tracking not yet implemented (FastAPI dependency injection needed)

### Exception Blocks Found:
**Total: 11 exception handlers** (1 bare except, 10 proper)

**Dangerous pattern identified:**
1. Line 73 - `broadcast_to_react()` - **BARE EXCEPT** catches KeyboardInterrupt! Should be `except Exception:`

**REST Endpoint Exception Handlers (all use track_error wrapper):**
2. Line 248 - `/chat` endpoint - Main chat processing
3. Line 272 - `/history` endpoint - Conversation history retrieval
4. Line 313 - `/errors` endpoint - Fallback error handling
5. Line 356 - `/memory/stats` endpoint - Memory statistics
6. Line 378 - `/memory/search` endpoint - Memory search
7. Line 434 - `/services/{service_name}/restart` - Service restart
8. Line 458 - `/services/group/{group_name}/start` - Service group start
9. Line 481 - `/services/autostart` - Auto-start services

**WebSocket Exception Handlers:**
10. Line 527 - WebSocketDisconnect - Proper disconnect handling
11. Line 529 - General exceptions - Uses track_error() wrapper

### Error Handling Pattern:
**Current approach: HYBRID - ErrorHandler + React Broadcasting** ‚úÖ

**The track_error() wrapper pattern:**
```python
def track_error(error_msg: str, operation_context: str = None, service: str = "api_server", severity: str = "normal"):
    """Track errors using centralized ErrorHandler and broadcast to React"""

    # Map string severity to ErrorSeverity enum
    severity_map = {
        "critical": ErrorSeverity.CRITICAL_STOP,
        "warning": ErrorSeverity.MEDIUM_ALERT,
        "normal": ErrorSeverity.MEDIUM_ALERT,
        "debug": ErrorSeverity.LOW_DEBUG
    }
    error_severity = severity_map.get(severity, ErrorSeverity.MEDIUM_ALERT)

    # Map service to ErrorCategory
    category_map = {
        "chat_processor": ErrorCategory.MESSAGE_PROCESSING,
        "api_server": ErrorCategory.SERVICE_CONNECTION,
        "websocket": ErrorCategory.SERVICE_CONNECTION,
        "memory_system": ErrorCategory.WORKING_MEMORY
    }
    error_category = category_map.get(service, ErrorCategory.GENERAL)

    # Use centralized error handler
    error_handler.handle_error(
        Exception(error_msg),
        error_category,
        error_severity,
        context=operation_context or "API operation",
        operation=service or "api_request"
    )

    # Broadcast to React for real-time updates
    asyncio.create_task(broadcast_to_react({
        "type": "error_update",
        "error": error_event.dict()
    }))
```

**Usage in endpoints:**
```python
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(message: ChatMessage):
    try:
        # process message
        return response
    except Exception as e:
        error_msg = f"Chat processing failed: {str(e)}"
        track_error(error_msg, f"chat_message: {message.message[:50]}...", "chat_processor", "critical")
        return ChatResponse(response="Sorry, I encountered an error", error=error_msg)
```

**What's good:**
- ‚úÖ Already integrates ErrorHandler via shared instance
- ‚úÖ Custom wrapper adds React broadcasting
- ‚úÖ Service/category mapping for error classification
- ‚úÖ Severity mapping for proper error levels
- ‚úÖ Operation context captured for debugging
- ‚úÖ WebSocket errors handled separately
- ‚úÖ Graceful fallback responses to React UI

**What needs improvement:**
- ‚ùå **BARE EXCEPT at line 73** - catches KeyboardInterrupt!
- ‚ö†Ô∏è No request ID tracking (FastAPI doesn't have Flask's g.request_id)
- ‚ö†Ô∏è track_error() creates Exception from string (loses original stack trace)

### Critical Operations Identified:
1. **chat_endpoint()** - Main chat processing (CRITICAL!)
2. **websocket_endpoint()** - Real-time updates to React
3. **broadcast_to_react()** - Error propagation to UI (currently has bare except!)
4. **track_error()** - Central error routing function
5. **Service management endpoints** - Restart/recovery operations

### Integration Plan:
**Recommended: 3 Small Fixes** ‚ö†Ô∏è

**Fix 1: Replace bare except (HIGH PRIORITY)**
```python
# BEFORE (line 73):
except:
    active_connections.remove(connection)

# AFTER:
except Exception:
    active_connections.remove(connection)
```

**Fix 2: Preserve original exception in track_error() (MEDIUM PRIORITY)**
```python
# Add optional parameter to track_error:
def track_error(error_msg: str, operation_context: str = None, service: str = "api_server", severity: str = "normal", original_exception: Exception = None):
    # Use original exception if provided, otherwise create from message
    error_exception = original_exception or Exception(error_msg)

    error_handler.handle_error(
        error_exception,
        error_category,
        error_severity,
        context=operation_context or "API operation",
        operation=service or "api_request"
    )
```

Then in usage:
```python
except Exception as e:
    track_error(f"Chat failed: {str(e)}", context, "chat_processor", "critical", original_exception=e)
```

**Fix 3: Add request ID tracking (LOW PRIORITY - FastAPI dependency injection pattern needed)**
```python
# Add middleware for request tracking:
from contextvars import ContextVar
import uuid

request_id_var: ContextVar[str] = ContextVar('request_id', default=None)

@app.middleware("http")
async def add_request_id(request: Request, call_next):
    request_id = str(uuid.uuid4())
    request_id_var.set(request_id)
    response = await call_next(request)
    response.headers["X-Request-ID"] = request_id
    return response
```

### What's Particularly Clever:
- **Hybrid Pattern**: Combines ErrorHandler (backend logging) + React broadcasting (UI updates)
- **Category Mapping**: Smart translation from service names to ErrorCategory enums
- **Severity Translation**: Maps user-friendly strings to ErrorSeverity enums
- **WebSocket Error Handling**: Separate logic for disconnect vs general errors
- **Shared ErrorHandler**: Single instance shared between api_server_bridge + rich_chat + service_manager

### Comparison to Other Services:
**This is unique - it's a BRIDGE, not a microservice:**
- Not Flask (it's FastAPI)
- Not a data service (it's an API gateway)
- Not independent (tightly coupled to rich_chat.py)
- Not running in Docker (runs alongside rich_chat in host)

**The pattern makes sense for its role:**
- Wraps ErrorHandler with React-specific broadcasting
- Acts as translator between React UI and rich_chat system
- Doesn't need Service class separation (thin wrapper around rich_chat)

### Questions/Concerns:
**Q:** Should we standardize on FastAPI middleware for request IDs?
**A:** Yes - would match episodic pattern's request tracking

**Q:** track_error() loses stack traces - is this a problem?
**A:** Minor - ErrorHandler still logs, but original exception context is lost

**Q:** Bare except at line 73 - how critical?
**A:** HIGH - Could mask KeyboardInterrupt during development/testing

---

## Overall Progress Tracker

**Last Updated:** November 25, 2025

**Error Centralization Completion:**
- ‚úÖ Audit Phase: **6/6 microservices (100%)** + **8 client-side files (100%)**
- ‚úÖ Integration Phase: **COMPLETE**
- ‚è≥ Testing Phase: In Progress
- **Overall: ~85% complete**

### Microservices Audited (October 2025):
1. ‚úÖ working_memory - Proper error handling, returns structured errors
2. ‚úÖ episodic_memory - GOLD STANDARD (no changes needed)
3. ‚úÖ memory_curator - GOLD STANDARD (no changes needed)
4. ‚úÖ mcp_logger - Proxy pattern (no changes needed)
5. ‚úÖ rich_chat - ErrorHandler integrated, bare except FIXED (Nov 25)
6. ‚úÖ api_server_bridge - Hybrid pattern, already had proper error_handler

### Client-Side Files Integration (November 25, 2025):
7. ‚úÖ **llm_connector.py** - Added optional error_handler, `_log_error()` helper, wired to rich_chat.py
8. ‚úÖ **memory_distillation.py** - Added optional error_handler, `_log_error()` helper, wired to rich_chat.py
9. ‚úÖ **conversation_file_management.py** - Added optional error_handler to both ConversationManager and FileManager classes
10. ‚úÖ **service_connector.py** - Added optional error_handler, `_log_error()` helper (MVP test script)
11. ‚úÖ **terminal_broadcaster.py** - SKIPPED: Standalone launcher, print is appropriate
12. ‚úÖ **terminal_broadcaster_pty.py** - SKIPPED: Standalone launcher, print is appropriate
13. ‚úÖ enhanced_chat.py - DEAD CODE (not imported anywhere)
14. ‚úÖ chat_interface.py - DEAD CODE (not imported anywhere)

### Completed Actions (November 25, 2025):

**TRIVIAL (Completed):**
1. [x] Fix rich_chat.py bare except (lines 576-580) - Changed to `except Exception as e:` with error_handler
2. [x] api_server_bridge.py - Verified already has proper error_handler integration

**LOW COMPLEXITY (Completed):**
3. [x] Add error_handler to llm_connector.py - Added `_log_error()`, updated SmartLLMSelector
4. [x] Add error_handler to memory_distillation.py - Added `_log_error()`, updated load/save handlers
5. [x] Add error_handler to conversation_file_management.py - Added to both classes, 4 handlers updated
6. [x] Add error_handler to service_connector.py - Added `_log_error()`, 5 handlers updated

**SKIPPED (Documented Decision):**
7. [x] terminal_broadcaster.py + pty version - Standalone infrastructure launchers, print to console is appropriate behavior for operators watching the terminal

### Remaining Actions:

**TESTING & DOCUMENTATION:**
1. [ ] Run ERROR_HANDLER_INTEGRATION_TESTING.md test sheet
2. [ ] Test error recovery for each service type
3. [ ] Document error categories and severities
4. [ ] Verify all errors flow to React error panel

**Total Time Spent:** ~2 hours (faster than estimated!)

---

## Standardization Plan (Active Work)

### **Standard Pattern: Episodic Memory Style**

After reviewing working_memory and episodic_memory, **episodic's pattern should be the standard for ALL services**:

**The Standard:**
```python
# 1. Service class with business logic
class ServiceName:
    def operation(self, data):
        try:
            # business logic
            return result
        except Exception as e:
            logger.error(f"Error in operation: {e}")
            raise  # Let Flask layer handle HTTP response

# 2. Flask endpoint with request tracking
@app.route('/endpoint', methods=['POST'])
def endpoint():
    try:
        result = service.operation(data)
        return jsonify({"status": "success", "result": result, "request_id": g.request_id})
    except Exception as e:
        logger.error(f"Error in endpoint (request: {g.request_id}): {e}")
        return jsonify({"status": "error", "message": str(e), "request_id": g.request_id}), 500
```

**Why This Matters:**
- ‚úÖ Separation of concerns (business logic vs HTTP layer)
- ‚úÖ Request ID tracking for debugging ‚Üê **Critical for {YOU} (LLMs) to trace errors**
- ‚úÖ Better testability (can test service class independently)
- ‚úÖ More maintainable (clear responsibility boundaries)
- ‚úÖ Consistent error handling across all services

**Apply Upgrades To:**
- [ ] working_memory/service.py - Add Service class + request IDs
- [ ] curator/service.py - TBD (audit in progress)
- [ ] mcp_logger/service.py - TBD (audit pending)
- [ ] api_server_bridge.py - TBD (audit pending)

**Estimated effort:** 2-3 hours per service

**Priority:** MEDIUM - Do during this error centralization push (we have time!)

---

## Key Patterns to Look For

During each audit, check for:

1. **Silent Failures**
   - Bare `except:` or `except Exception:` with `pass`
   - Operations that could lose data without alerting

2. **Critical Operations**
   - Database writes
   - Memory storage/retrieval
   - User data handling
   - Authentication/authorization

3. **Current Error Handling**
   - Are errors logged?
   - Are errors returned to caller?
   - Are errors displayed to user?

4. **Integration Approach**
   - Does service need ErrorHandler class?
   - Or just better logging?
   - Or structured error responses?

---

## Decision Framework

**For each service, decide:**

### Option A: Full ErrorHandler Integration
**When:** Service is tightly coupled with rich_chat or UI
- Import ErrorHandler
- Wrap critical operations
- Route errors to centralized handler

### Option B: Structured Logging Only
**When:** Service is independent microservice
- Use Python logging properly
- Return structured error responses
- Let calling service handle user-facing errors

### Option C: Hybrid Approach
**When:** Service needs both local logging and central reporting
- Log locally for service debugging
- Return structured errors to caller
- Caller decides what to escalate to ErrorHandler

---

## Next Steps

1. Audit working_memory service (CURRENT)
2. Fill in findings for working_memory
3. Decide integration approach
4. Move to next service
5. Repeat until all 6 complete

---

**Last Updated:** November 25, 2025
**Updated By:** Claude + Operator (pair programming session)

**November 25 Update:** Completed client-side error_handler integration for llm_connector.py, memory_distillation.py, conversation_file_management.py, and service_connector.py. Documented decision to skip terminal_broadcaster files (standalone launchers). Fixed rich_chat.py bare except. Integration phase complete, moving to testing phase.
